{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classic Control\n",
    "\n",
    "### CartPole (v1)\n",
    "\n",
    "_A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track.  \n",
    "The system is controlled by applying a force of +1 or -1 to the cart.  \n",
    "The pendulum starts upright, and the goal is to prevent it from falling over.  \n",
    "A reward of +1 is provided for every step that the pole remains upright.  \n",
    "The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center._\n",
    "\n",
    "[Environment Source code (GitHub)](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space type: <class 'gym.spaces.box.Box'>\n",
      "Observation space size: (4,) * float32\n",
      "Observation space max values: [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "Observation space min values: [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
      "Reward range: (-inf, inf)\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of environment\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "print(\"Observation space type:\", type(env.observation_space))\n",
    "print(\"Observation space size:\", env.observation_space.shape, \"*\", env.observation_space.dtype)\n",
    "print(\"Observation space max values:\", env.observation_space.high)\n",
    "print(\"Observation space min values:\", env.observation_space.low)\n",
    "print(\"Reward range:\", env.reward_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation Space - _Box(4)_\n",
    "\n",
    "| Index | Observation Type     | Min Value           | Max Value         |\n",
    "| :---: | -------------------- | :-----------------: | :---------------: |\n",
    "| 0     | Cart Position        | -4.8                | 4.8               |\n",
    "| 1     | Cart Velocity        | _-Inf_              | _Inf_             |\n",
    "| 2     | Pole Angle           | -0.41887 rad (-24°) | 0.41887 rad (24°) |\n",
    "| 3     | Pole Velocity At Tip | _-Inf_              | _Inf_             |\n",
    "\n",
    "### Action Space - _Discrete(2)_\n",
    "\n",
    "| Index | Action Type            |\n",
    "| :---: | ---------------------- |\n",
    "| 0     | Push Cart to the Left  |\n",
    "| 1     | Push Cart to the Right |\n",
    "\n",
    "### Reward\n",
    "Reward is 1 for every step taken, including the termination step. The threshold is 475.\n",
    "\n",
    "### Starting State\n",
    "![image](https://user-images.githubusercontent.com/53531617/148705742-ec6e0832-1f2d-422b-adce-9f1af5a264dc.png)\n",
    "\n",
    "### Termination Conditions\n",
    "1) Pole Angle is more than ±12°  \n",
    "2) Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)  \n",
    "3) Episode length is greater than 200 (500 for v1)  \n",
    "\n",
    "### Solved Requirements\n",
    "Considered solved when the average reward is greater than or equal to 195.0 over 100 consecutive trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def play(agent):\n",
    "    # Initialize the environment state (uniform random value between ±0.05)\n",
    "    current_state = env.reset()\n",
    "    \n",
    "    for _ in range(500):\n",
    "        action = agent.get_action()\n",
    "        env.step(action)\n",
    "        env.render()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\paulo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py:150: UserWarning: \u001B[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001B[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "from RandomAgent import *\n",
    "\n",
    "random_agent = RandomAgent(env)\n",
    "play(random_agent)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}