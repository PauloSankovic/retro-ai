@Book{CupicUvod,
  author = 	 {Marko Čupić},
  title = 	 {{Umjetna Inteligencija - Uvod u strojno učenje}},
  year = 	 {2022},
  note =     { http://java.zemris.fer.hr/nastava/ui/ml/ml-20220430.pdf }
}

@misc{wikiRL,
   author = "Wikipedia",
   title = "{Reinforcement learning} --- {W}ikipedia{,} The Free Encyclopedia",
   year = "2022",
   howpublished = {\url{http://en.wikipedia.org/w/index.php?title=Reinforcement\%20learning&oldid=1090221087}},
   note = "Pristupljeno 25. lipnja 2022."
 }

@misc{OpenAIWhitepaper,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@article{OpenAIALE,
  author = {{Bellemare}, M.~G. and {Naddaf}, Y. and {Veness}, J. and {Bowling}, M.},
  title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
  journal = {Journal of Artificial Intelligence Research},
  year = "2013",
  month = "jun",
  volume = "47",
  pages = "253--279",
}

@article{NNsvg,
  doi = {10.21105/joss.00747},
  url = {https://doi.org/10.21105/joss.00747},
  year = {2019},
  publisher = {The Open Journal},
  volume = {4},
  number = {33},
  pages = {747},
  author = {Alexander LeNail},
  title = {NN-SVG: Publication-Ready Neural Network Architecture Schematics},
  journal = {Journal of Open Source Software}
}

@article{AleDeterministic,
  author    = {Marlos C. Machado and
               Marc G. Bellemare and
               Erik Talvitie and
               Joel Veness and
               Matthew J. Hausknecht and
               Michael Bowling},
  title     = {Revisiting the Arcade Learning Environment: Evaluation Protocols and
               Open Problems for General Agents},
  journal   = {CoRR},
  volume    = {abs/1709.06009},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.06009},
  eprinttype = {arXiv},
  eprint    = {1709.06009},
  timestamp = {Mon, 13 Aug 2018 16:47:17 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1709-06009.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DLBook,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@misc{MediumDeterministic, 
    title={Are the space invaders deterministic or stochastic?},
    url={https://towardsdatascience.com/are-the-space-invaders-deterministic-or-stochastic-595a30becae2}, 
    journal={Medium}, 
    publisher={Towards Data Science}, 
    author={Maquaire, Nicolas}, 
    year={2020}, 
    month={Sep}
} 

@misc{BaselinesVecEnvs, 
    title={Vectorized Environments}, 
    url={https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html}, 
    journal={Vectorized Environments - Stable Baselines3 documentation}
}

@misc{CartPoleValues, 
    title={How to beat the Cartpole game in 5 lines}, 
    url={https://towardsdatascience.com/how-to-beat-the-cartpole-game-in-5-lines-5ab4e738c93f}, 
    journal={Medium}, 
    publisher={Towards Data Science}, 
    author={Xu, Jian}, 
    year={2021}, month={Feb}
}

@misc{RLAlgos, 
    title={Part 2: Kinds of RL algorithms}, 
    url={https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html}, 
    journal={Part 2: Kinds of RL Algorithms - Spinning Up documentation},
    note="Pristupljeno 25. lipnja 2022."
} 

@article{DQL,
	Title = {Human-level control through deep reinforcement learning},
	Author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	DOI = {10.1038/nature14236},
	Number = {7540},
	Volume = {518},
	Month = {February},
	Year = {2015},
	Journal = {Nature},
	ISSN = {0028-0836},
	Pages = {529—533},
	URL = {https://doi.org/10.1038/nature14236},
}

@misc{DDQL,
  doi = {10.48550/ARXIV.1509.06461},
  url = {https://arxiv.org/abs/1509.06461},
  author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Deep Reinforcement Learning with Double Q-learning},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{SB3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1--8},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
}

@misc{sb3-alg-repo,
  author = {Raffin, Antonin},
  title = {RL Baselines3 Zoo},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/DLR-RM/rl-baselines3-zoo}},
}

@misc{DQN-impl, 
 title={Deep Learning Paper Implementations},
 url={https://nn.labml.ai/rl/dqn/index.html}, 
 journal={Deep Q Networks (DQN)}
} 

@article{A2C,
  author    = {Volodymyr Mnih and
               Adri{\`{a}} Puigdom{\`{e}}nech Badia and
               Mehdi Mirza and
               Alex Graves and
               Timothy P. Lillicrap and
               Tim Harley and
               David Silver and
               Koray Kavukcuoglu},
  title     = {Asynchronous Methods for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1602.01783},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.01783},
  eprinttype = {arXiv},
  eprint    = {1602.01783},
  timestamp = {Mon, 13 Aug 2018 16:47:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MnihBMGLHSK16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{DoubleDunk, 
  url={https://www.gymlibrary.ml/environments/atari/double_dunk/}, 
  journal={Gymlibrary.ml}
} 

@misc{SpaceInvaders, 
  url={https://www.gymlibrary.ml/environments/atari/space_invaders/}, 
  journal={Gymlibrary.ml}
} 

@misc{CarRacing, 
  url={https://www.gymlibrary.ml/environments/box2d/car_racing/}, 
  journal={Gymlibrary.ml}
} 

@misc{Pong, 
  url={https://www.gymlibrary.ml/environments/atari/pong/}, 
  journal={Gymlibrary.ml}
} 

@misc{GymAnytrading,
  title={AMINHP/Gym-anytrading: The most simple, flexible, and Comprehensive Openai Gym Trading Environment (approved by Openai Gym)}, 
  url={https://github.com/AminHP/gym-anytrading}, 
  journal={GitHub}, 
  author={AminHP}
} 

@misc{Tensortrade,
  title={Tensortrade-org/tensortrade: An open source reinforcement learning framework for training, evaluating, and deploying robust trading agents.}, 
  url={https://github.com/tensortrade-org/tensortrade}, 
  journal={GitHub}, 
  author={Tensortrade-Org}
} 

@misc{CustomDinoGame,
  title={Build a Chrome Dino Game AI Model with Python | AI Learns to Play Dino Game}, 
  url={https://www.youtube.com/watch?v=vahwuupy81A}, 
  journal={YouTube}, 
  author={Nicholas Renotte}
} 

@misc{CustomFlappyBird,
  title={Flappy Bird for OpenAI Gym}, 
  url={https://github.com/Talendar/flappy-bird-gym}, 
  journal={GitHub}, 
  author={Talendar}
} 

@unpublished{PodUceFer,
  author={Kostanjčar, Zvonko},
  Institution = {Sveučilište u Zagrebu, Fakultet elektrotehnike i računarstva},
  title={Predavanja - Podržano učenje}, 
  Howpublished = {University Lecture},
  Year = {2021}
} 
 
@misc{SpinningUp,
 title={Part 1: Key concepts in RL},
 url={https://spinningup.openai.com/en/latest/spinningup/rl_intro.html}, 
 journal={Part 1: Key Concepts in RL - Spinning Up documentation}
}

@misc{AtariBreakout, 
 title={Breakout - Atari - Atari 2600 }, 
 url={https://atariage.com/manual_html_page.php?SoftwareID=889}, 
 journal={AtariAge News RSS}
} 

@misc{GymStart,
 title={Getting started with Openai Gym},
 url={https://blog.paperspace.com/getting-started-with-openai-gym/}, 
 journal={Paperspace Blog}, 
 publisher={Paperspace Blog}, 
 author={Kathuria, Ayoosh}, 
 year={2021}, month={Apr}
} 

@unpublished{StruceFer,
  author={Šnajder, Jan},
  Institution = {Sveučilište u Zagrebu, Fakultet elektrotehnike i računarstva},
  title={Strojno učenje: 2. Osnovni koncepti}, 
  Howpublished = {University Lecture},
  Year = {2020}
} 

@unpublished{DubuceFer,
  author={Čupić, Marko},
  Institution = {Sveučilište u Zagrebu, Fakultet elektrotehnike i računarstva},
  title={Duboko učenje - Optimizacija parametara modela}, 
  Howpublished = {University Lecture},
  Year = {2019}
} 

@misc{QL, 
 title={Reinforcement learning with (deep) Q-learning explained},
 url={https://www.assemblyai.com/blog/reinforcement-learning-with-deep-q-learning-explained/}, 
 journal={News, Tutorials, AI Research}, 
 publisher={News, Tutorials, AI Research}, 
 author={Loeber, Patrick}, 
 year={2022}, 
 month={Feb}
}

@online{BruntonYoutube,
 title = {Q-Learning: Model Free Reinforcement Learning and Temporal Difference Learning},
 date = {2022},
 organization = {Youtube},
 author = {Steve Brunton},
 url = {https://www.youtube.com/watch?v=0iqz4tcKN58},
}

@misc{QLStructure, 
 title={Deep Q-learning: An introduction to deep reinforcement learning},
 url={https://www.analyticsvidhya.com/blog/2019/04/introduction-deep-q-learning-python/},
 journal={Analytics Vidhya}, 
 year={2020}, 
 month={Apr}
}

@misc{DQN-MlAi, 
 url={https://nn.labml.ai/rl/dqn/index.html}, 
 journal={Deep Q Networks (DQN)}, 
 publisher={labml.ai}
}

@misc{PolicyGrad, 
 title={Deriving policy gradients and implementing reinforce},
 url={https://medium.com/@thechrisyoon/deriving-policy-gradients-and-implementing-reinforce-f887949bd63},
 journal={Medium}, 
 publisher={Medium}, 
 author={Yoon, Chris}, 
 year={2019}, 
 month={May}
}

@misc{AC, 
 title={The idea behind actor-critics and how A2c and A3C improve them},
 url={https://theaisummer.com/Actor_critics/}, 
 journal={AI Summer}, 
 publisher={Sergios Karagiannakos}, 
 author={Sergios Karagiannakos}, 
 year={2018}, 
 month={Nov}
}

@misc{pg-methods, 
 title={Deep Reinforcement Learning and control fall 2018, CMU 10703 - Policy Gradient Methods},
 url={https://www.andrew.cmu.edu/course/10-703/}, 
 journal={CMU 10703: Deep RL and Control}
}

@misc{ac-arch, 
 title={Actor-Critic Methods}, 
 url={http://www.incompleteideas.net/book/ebook/node66.html}, 
 journal={6.6 actor-critic methods}
}

@misc{A2C-tensorflow, 
 title={Playing Cartpole with the actor-critic method},
 url={https://www.tensorflow.org/tutorials/reinforcement_learning/actor_critic}, 
 journal={TensorFlow}
} 
