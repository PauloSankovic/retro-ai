@Book{CupicUvod,
  author = 	 {Marko Čupić},
  title = 	 {{Umjetna Inteligencija - Uvod u strojno učenje}},
  year = 	 {2022},
  note =     { http://java.zemris.fer.hr/nastava/ui/ml/ml-20220430.pdf }
}

@misc{wikiRL,
   author = "Wikipedia",
   title = "{Reinforcement learning} --- {W}ikipedia{,} The Free Encyclopedia",
   year = "2022",
   howpublished = {\url{http://en.wikipedia.org/w/index.php?title=Reinforcement\%20learning&oldid=1090221087}},
   note = "Pristupljeno 25. lipnja 2022."
 }

@misc{OpenAIWhitepaper,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@article{OpenAIALE,
  author = {{Bellemare}, M.~G. and {Naddaf}, Y. and {Veness}, J. and {Bowling}, M.},
  title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
  journal = {Journal of Artificial Intelligence Research},
  year = "2013",
  month = "jun",
  volume = "47",
  pages = "253--279",
}

@article{NNsvg,
  doi = {10.21105/joss.00747},
  url = {https://doi.org/10.21105/joss.00747},
  year = {2019},
  publisher = {The Open Journal},
  volume = {4},
  number = {33},
  pages = {747},
  author = {Alexander LeNail},
  title = {NN-SVG: Publication-Ready Neural Network Architecture Schematics},
  journal = {Journal of Open Source Software}
}

@article{AleDeterministic,
  author    = {Marlos C. Machado and
               Marc G. Bellemare and
               Erik Talvitie and
               Joel Veness and
               Matthew J. Hausknecht and
               Michael Bowling},
  title     = {Revisiting the Arcade Learning Environment: Evaluation Protocols and
               Open Problems for General Agents},
  journal   = {CoRR},
  volume    = {abs/1709.06009},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.06009},
  eprinttype = {arXiv},
  eprint    = {1709.06009},
  timestamp = {Mon, 13 Aug 2018 16:47:17 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1709-06009.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DLBook,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@misc{MediumDeterministic, 
    title={Are the space invaders deterministic or stochastic?},
    url={https://towardsdatascience.com/are-the-space-invaders-deterministic-or-stochastic-595a30becae2}, 
    journal={Medium}, 
    publisher={Towards Data Science}, 
    author={Maquaire, Nicolas}, 
    year={2020}, 
    month={Sep}
} 

@misc{BaselinesVecEnvs, 
    title={Vectorized Environments}, 
    url={https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html}, 
    journal={Vectorized Environments - Stable Baselines 2.10.2 documentation}
}

@misc{CartPoleValues, 
    title={How to beat the Cartpole game in 5 lines}, 
    url={https://towardsdatascience.com/how-to-beat-the-cartpole-game-in-5-lines-5ab4e738c93f}, 
    journal={Medium}, 
    publisher={Towards Data Science}, 
    author={Xu, Jian}, 
    year={2021}, month={Feb}
}

@misc{RLAlgos, 
    title={Part 2: Kinds of RL algorithms}, 
    url={https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html}, 
    journal={Part 2: Kinds of RL Algorithms - Spinning Up documentation},
    note="Pristupljeno 25. lipnja 2022."
} 

@article{DQL,
	Title = {Human-level control through deep reinforcement learning},
	Author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	DOI = {10.1038/nature14236},
	Number = {7540},
	Volume = {518},
	Month = {February},
	Year = {2015},
	Journal = {Nature},
	ISSN = {0028-0836},
	Pages = {529—533},
	URL = {https://doi.org/10.1038/nature14236},
}

@misc{DDQL,
  doi = {10.48550/ARXIV.1509.06461},
  url = {https://arxiv.org/abs/1509.06461},
  author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Deep Reinforcement Learning with Double Q-learning},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{SB3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1--8},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
}

@misc{sb3-alg-repo,
  author = {Raffin, Antonin},
  title = {RL Baselines3 Zoo},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/DLR-RM/rl-baselines3-zoo}},
}

@misc{DQN-impl, 
 title={Deep Learning Paper Implementations},
 url={https://nn.labml.ai/rl/dqn/index.html}, 
 journal={Deep Q Networks (DQN)}
} 

@article{A2C,
  author    = {Volodymyr Mnih and
               Adri{\`{a}} Puigdom{\`{e}}nech Badia and
               Mehdi Mirza and
               Alex Graves and
               Timothy P. Lillicrap and
               Tim Harley and
               David Silver and
               Koray Kavukcuoglu},
  title     = {Asynchronous Methods for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1602.01783},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.01783},
  eprinttype = {arXiv},
  eprint    = {1602.01783},
  timestamp = {Mon, 13 Aug 2018 16:47:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MnihBMGLHSK16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{DoubleDunk, 
  url={https://www.gymlibrary.ml/environments/atari/double_dunk/}, 
  journal={Gymlibrary.ml}
} 

@misc{SpaceInvaders, 
  url={https://www.gymlibrary.ml/environments/atari/space_invaders/}, 
  journal={Gymlibrary.ml}
} 

@misc{CarRacing, 
  url={https://www.gymlibrary.ml/environments/box2d/car_racing/}, 
  journal={Gymlibrary.ml}
} 

@misc{Pong, 
  url={https://www.gymlibrary.ml/environments/atari/pong/}, 
  journal={Gymlibrary.ml}
} 

@misc{GymAnytrading,
  title={AMINHP/Gym-anytrading: The most simple, flexible, and Comprehensive Openai Gym Trading Environment (approved by Openai Gym)}, 
  url={https://github.com/AminHP/gym-anytrading}, 
  journal={GitHub}, 
  author={AminHP}
} 

@misc{Tensortrade,
  title={Tensortrade-org/tensortrade: An open source reinforcement learning framework for training, evaluating, and deploying robust trading agents.}, 
  url={https://github.com/tensortrade-org/tensortrade}, 
  journal={GitHub}, 
  author={Tensortrade-Org}
} 

@misc{CustomDinoGame,
  title={Build a Chrome Dino Game AI Model with Python | AI Learns to Play Dino Game}, 
  url={https://www.youtube.com/watch?v=vahwuupy81A}, 
  journal={YouTube}, 
  author={Nicholas Renotte}
} 

@misc{CustomFlappyBird,
  title={Flappy Bird for OpenAI Gym}, 
  url={https://github.com/Talendar/flappy-bird-gym}, 
  journal={GitHub}, 
  author={Talendar}
} 
