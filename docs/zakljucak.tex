\chapter{Zaključak}

U ovom radu proučena je i opisana problematika podržanog učenja gdje se bez znanja o pravilima i funkcioniranju specifične okoline, želi konstruirati agent kojemu je cilj pronaći optimalnu strategiju koja maksimizira očekivanu dobit u određenom vremenskom okviru. Agenti koji se prilično dobro ponašaju u takvim okolinama implementirani su pomoću različitih algoritama podržanog učenja koji se temelje na umjetnim neuronskim mrežama - jako dobrim univerzalnim aproksimatorima funkcija.

Proučeni su i opisani osnovniji modeli i ideje algoritama dubokog Q učenja, dvostrukog dubokog Q učenja, prednosnog akter-kritičara i popratnih inačica. Interakcijom i evaluacijom agenata koji su smješteni u posebnim okolinama, zapažene su prednosti i mane svakog od njih te su postignuti rezultati bliski onima \textit{state-of-the-art} algoritama i implementacija. 

Veliki broj algoritama, inačica, implementacija i dodataka čine podržano učenje izrazito velikim i iscrpnim područjem s velikim brojem primjena u stvarnom životu.

Podržano učenje duboko je inspirirano načinom kako ljudi i ostala živa bića uče iz iskustva pri interakciji s okolinom. Napretkom tehnologije, ideje umjetnih neuronskih mreža i algoritama, te razvitkom agenata koji u posebnim radnim okvirima interaktiraju s okolinom, sve smo bliži razvoju sustava opće umjetne inteligencije koje nije ograničeno na svoj strogi skup znanja koja mu definiraju samo jednu zadaću ili područje rada. Sve smo bliži tome da umjetna inteligencija bude inteligentna - sposobna učiti iz iskustva, prilagoditi se novim do sad neviđenim situacijama, razumjeti ih, iz konteksta učiti pravila koja definiraju ponašanje okoline te izvršavati zadatke i akcije koji su definirani tim pravilima na optimalan i posljedično koristan način.